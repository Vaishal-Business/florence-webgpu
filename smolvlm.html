<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<title>SmolVLM WebGPU Demo</title>
<script src="https://cdn.jsdelivr.net/npm/onnxruntime-web/dist/ort.min.js"></script>
<style>
  body { font-family: Arial; padding: 20px; background: #111; color: #eee; }
  input, button { margin: 10px 0; }
  img { max-width: 300px; display: block; margin: 10px 0; }
  pre { background: #222; padding: 10px; }
</style>
</head>
<body>

<h1>SmolVLM WebGPU Demo</h1>

<label>Upload ONNX model:</label>
<input type="file" id="onnxUpload" accept=".onnx"><br>

<label>Upload image:</label>
<input type="file" id="imageUpload" accept="image/*"><br>

<input type="text" id="prompt" placeholder="Enter your prompt" value="extract the text from image accurately"><br>

<button id="runBtn">Run Model</button>

<img id="preview" src="" alt="Uploaded image preview">
<pre id="output"></pre>

<script>
let session = null;
let modelLoaded = false;

// Handle ONNX model upload
document.getElementById('onnxUpload').addEventListener('change', async (evt) => {
    const file = evt.target.files[0];
    if (!file) return;

    document.getElementById('output').textContent = 'Loading model...';
    const arrayBuffer = await file.arrayBuffer();
    session = await ort.InferenceSession.create(arrayBuffer, { executionProviders: ['webgpu'] });
    modelLoaded = true;
    document.getElementById('output').textContent = 'Model loaded! Ready to run inference.';
});

// Handle image upload preview
document.getElementById('imageUpload').addEventListener('change', (evt) => {
    const file = evt.target.files[0];
    if (!file) return;
    const img = document.getElementById('preview');
    img.src = URL.createObjectURL(file);
});

// Resize image to 160x160
function resizeImage(img) {
    const canvas = document.createElement('canvas');
    const size = 160;
    canvas.width = size;
    canvas.height = size;
    const ctx = canvas.getContext('2d');
    ctx.drawImage(img, 0, 0, size, size);
    return ctx.getImageData(0, 0, size, size);
}

// Convert ImageData to Float32Array (C,H,W)
function imageDataToTensor(imageData) {
    const { data, width, height } = imageData;
    const floatData = new Float32Array(3 * width * height);
    for (let y = 0; y < height; y++) {
        for (let x = 0; x < width; x++) {
            const idx = (y * width + x) * 4;
            const i = y * width + x;
            floatData[i] = data[idx] / 255;                 // R
            floatData[width*height + i] = data[idx+1] / 255; // G
            floatData[2*width*height + i] = data[idx+2] / 255; // B
        }
    }
    return floatData;
}

// Run model
document.getElementById('runBtn').addEventListener('click', async () => {
    if (!modelLoaded) {
        alert('Upload an ONNX model first!');
        return;
    }
    const imgEl = document.getElementById('preview');
    if (!imgEl.src) {
        alert('Upload an image first!');
        return;
    }

    const prompt = document.getElementById('prompt').value || "extract the text from image accurately";

    const img = new Image();
    img.src = imgEl.src;
    await new Promise(r => img.onload = r);

    const imageData = resizeImage(img);
    const pixelValues = imageDataToTensor(imageData);

    // Dummy input_ids for demo
    const inputIds = new BigInt64Array([0n]); // note the 'n' at the end

    const feeds = {
        pixel_values: new ort.Tensor('float32', pixelValues, [1,3,160,160]),
        input_ids: new ort.Tensor('int64', inputIds, [1,1])
    };

    const t0 = performance.now();
    const results = await session.run(feeds);
    const t1 = performance.now();

    document.getElementById('output').textContent =
        `Inference done in ${(t1 - t0).toFixed(2)} ms\n` +
        `Model output keys: ${Object.keys(results).join(', ')}`;
});
</script>

</body>
</html>
